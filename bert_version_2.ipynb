{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Qp5Jw4P5ghh"
   },
   "source": [
    "### Load Train and Test Data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqbue7Vl5aS3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "U11WeGBa6YBd"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'data/trainSet.csv',\n",
    "    names=['search_term', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "oujpVOyW6ydw",
    "outputId": "b99baaca-34c2-4b96-ca24-8655f8a64c6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_term</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yew hedge</td>\n",
       "      <td>1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fire detection shop</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cheap couch roll</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extra watermelon gum</td>\n",
       "      <td>1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>used generators for sale uk</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   search_term  category\n",
       "0                    yew hedge      1221\n",
       "1          fire detection shop        19\n",
       "2             cheap couch roll       398\n",
       "3         extra watermelon gum      1108\n",
       "4  used generators for sale uk       213"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7gKvJ2BCqz6I"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_table('data/candidateTestSet.txt', names=['search_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "V52unGrzq38V",
    "outputId": "ec2b9239-d965-48d3-9a76-5ffe66171cc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twister picnic blanket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best stop smoking app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phosphorus fertiliser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tattoo books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>child's desk chair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              search_term\n",
       "0  twister picnic blanket\n",
       "1   best stop smoking app\n",
       "2   phosphorus fertiliser\n",
       "3            tattoo books\n",
       "4      child's desk chair"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "edrxZPjn6yvh"
   },
   "outputs": [],
   "source": [
    "# list of unique existing categories\n",
    "possible_labels = df.category.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdilSjSq671N",
    "outputId": "7ebc44bc-305f-40c2-f846-e087071b411c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_LABELS = len(possible_labels) \n",
    "TOTAL_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2YWWuGz6_BH"
   },
   "source": [
    "### Training/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Rjr4bWkqmWTH"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df.index.values,\n",
    "    df.category.values,\n",
    "    test_size=0.1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=df.category.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3ms326BB7Mwl"
   },
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "nfwPqdxK7R0L",
    "outputId": "e3066fbf-830e-4edd-a5e2-21b7fa25ae3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>train</th>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <th>val</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1417</th>\n",
       "      <th>train</th>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1418</th>\n",
       "      <th>train</th>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2837 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    search_term\n",
       "category data_type             \n",
       "0        train              408\n",
       "         val                 45\n",
       "1        train              364\n",
       "         val                 40\n",
       "2        train              524\n",
       "...                         ...\n",
       "1416     val                 50\n",
       "1417     train              469\n",
       "         val                 52\n",
       "1418     train              408\n",
       "         val                 45\n",
       "\n",
       "[2837 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "df.groupby(['category', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Tb2fCZrQ7R3Y"
   },
   "outputs": [],
   "source": [
    "train_df = df[df.data_type=='train']\n",
    "val_df = df[df.data_type=='val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "JS_1RPoO7eLS",
    "outputId": "20dcba3e-2680-407d-fbe3-67be1bd94d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# search for max sequence length\n",
    "seq_len = [len(i.split()) for i in train_df.search_term]\n",
    "pd.Series(seq_len).hist(bins = 30)\n",
    "max_length = 0\n",
    "for i in seq_len:\n",
    "    if i > max_length:\n",
    "        max_length = i\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWZTXYLX7l33"
   },
   "source": [
    "### Task 4: Loading Tokenizer and encoding our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1Bpv1aNt7myf"
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "q_a_erde7tD9"
   },
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type==\"train\"].search_term.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=12,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type==\"val\"].search_term.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=12,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train[\"input_ids\"] \n",
    "attention_masks_train = encoded_data_train[\"attention_mask\"] \n",
    "labels_train = torch.tensor(df[df.data_type==\"train\"].category.values)\n",
    "\n",
    "input_ids_val = encoded_data_val[\"input_ids\"]\n",
    "attention_masks_val = encoded_data_val[\"attention_mask\"]\n",
    "labels_val = torch.tensor(df[df.data_type==\"val\"].category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HZtJT0gh7vbB"
   },
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train,\n",
    "                              attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val,\n",
    "                            attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdE8JrJm7y07",
    "outputId": "f3dac87a-1d61-4c66-cb1e-8449065da72a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546140"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okV0vFe370-h",
    "outputId": "1068b93f-e090-4f01-8a97-cf3f6996c7e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60683"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHhPy3gR8TiY"
   },
   "source": [
    "### Create PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9Y0pB-L_8UWp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Pzbge5gY8Qyw"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=SequentialSampler(dataset_val),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R79fdnY98LUL"
   },
   "source": [
    "### Setting up BERT Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFb8NQpU8MAS",
    "outputId": "bd5991f2-2f4d-47a4-e33b-30cb8d20e382"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    PRE_TRAINED_MODEL_NAME,\n",
    "    num_labels = TOTAL_LABELS,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NJtpwEURiWIv"
   },
   "outputs": [],
   "source": [
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhe7oS1adIic",
    "outputId": "077ab325-3096-41c5-d179-430a6c3dad0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                        (1419, 768)\n",
      "classifier.bias                                              (1419,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWPdihhf8kZa"
   },
   "source": [
    "## Setting Up Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BGJeSK3U8g05"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "L_e3-Xff8mgQ"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=5e-5, \n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2S3I5zLy8elr"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "scheduler = get_linear_schedule_with_warmup( \n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps = len(dataloader_train)*EPOCHS \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMZ0tPPG85Ru"
   },
   "source": [
    "### Task 8: Defining our Performance Metrics\n",
    "\n",
    "#### Accuracy metric approach originally used in accuracy function in [this tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/#41-bertforsequenceclassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zua8x7La81JH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "U5QjiMa987cu"
   },
   "outputs": [],
   "source": [
    "# we using f-1 score because we know about class imbalance.\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "4tGk8BHV9BuM"
   },
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_acc = {} \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        label_acc[label] = len(y_preds[y_preds==label])/len(y_true) \n",
    "    return label_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6gtFEbZ9JaX"
   },
   "source": [
    "### Training our model\n",
    "\n",
    "#### Approach adopted from an older version of HuggingFace's run_glue.py script. [Here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "UNC7SPES9Yvu"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  \n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(dataloader_train):\n",
    "    \n",
    "        # progress update after every 5000 batches.\n",
    "        if step % 5000 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(dataloader_train)))\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(dataloader_train)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "csLI7bsB9T-L"
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    avg_loss = total_loss/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return avg_loss, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKwp039coiK4",
    "outputId": "0a9e9a3c-c2be-4d2d-f036-b3d8ffc7016a"
   },
   "outputs": [],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# store training and validation loss of each epoch\n",
    "history = {'train_loss': {}, 'val_loss': {}}\n",
    "\n",
    "# for each epoch\n",
    "for epoch in range(EPOCHS):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, EPOCHS))\n",
    "    \n",
    "    # train model\n",
    "    train_loss = train()\n",
    "    \n",
    "    # evaluate model\n",
    "    valid_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    \n",
    "    # save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'model/bert_version_2_saved_weights.pt')\n",
    "    \n",
    "    # training and validation loss\n",
    "    history['train_loss'][epoch] = train_loss\n",
    "    history['val_loss'][epoch] =  valid_loss\n",
    "\n",
    "    print(f'\\nTraining Loss:     {train_loss:.3f}')\n",
    "    print(f'Validation Loss:     {valid_loss:.3f}')\n",
    "    print(f'F1 Score (Weighted): {val_f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9HuUp54IA6t",
    "outputId": "ac6fc55b-93c9-4465-ae9a-841897538c99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights of best model\n",
    "path = 'model/bert_version_2_saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1KJom8-lgQTV"
   },
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "A1OhAJ4Vg00D"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training and validation loss per epoch: ', history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_version_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
